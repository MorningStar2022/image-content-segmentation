import os
import numpy as np
from PIL import Image
from scipy.ndimage import binary_dilation
import cv2
from tqdm import tqdm
from sklearn.metrics import precision_recall_curve

# ===================== é…ç½®å‚æ•° =====================
GT_DIR = "/home/tjq/PycharmProjects/Hi-SAM-main/datasets/TotalText/groundtruth_pixel/Test"  # çœŸå€¼æ©ç ç›®å½•
PRED_DIR = "/home/tjq/PycharmProjects/Hi-SAM-main/datasets/TotalText/predict/Test"  # é¢„æµ‹æ©ç ç›®å½•
IMG_EXT = [".png", ".jpg", ".jpeg"]  # TotalTextæ©ç å¤šä¸ºpngæ ¼å¼
DISTANCE_THRESHOLD = 1  # é‚»åŸŸåŒ¹é…é˜ˆå€¼ï¼ˆ3Ã—3ï¼‰
SIGMA = 1.0  # é«˜æ–¯æ¨¡ç³Šæ ¸ï¼ˆç”Ÿæˆæ¦‚ç‡å›¾ï¼‰


# ===================== æ ¸å¿ƒå·¥å…·å‡½æ•° =====================
def load_mask(path, is_gt=False):
    """
    åŠ è½½æ©ç ï¼ˆé€‚é…TotalTextæ ¼å¼ï¼‰ï¼š
    - çœŸå€¼æ©ç ï¼šæ–‡æœ¬åŒºåŸŸ=255ï¼ŒèƒŒæ™¯=0 â†’ è½¬ä¸º1/0
    - é¢„æµ‹æ©ç ï¼šæ–‡æœ¬åŒºåŸŸ=ä»»æ„éé›¶å€¼ï¼ŒèƒŒæ™¯=0 â†’ è½¬ä¸º1/0
    """
    try:
        # åŠ è½½ä¸ºç°åº¦å›¾
        img = Image.open(path).convert("L")
        mask = np.array(img)

        # çœŸå€¼æ©ç å¤„ç†ï¼š255â†’1ï¼Œ0â†’0
        if is_gt:
            mask = (mask == 255).astype(np.uint8)
        # é¢„æµ‹æ©ç å¤„ç†ï¼šéé›¶â†’1ï¼Œ0â†’0
        else:
            mask = (mask > 0).astype(np.uint8)

        return mask
    except Exception as e:
        print(f"åŠ è½½æ©ç å¤±è´¥ {path}ï¼š{str(e)[:80]}")
        return None


def edge_matching(fg_gt, fg_pred, distance=DISTANCE_THRESHOLD):
    """
    å‰æ™¯åŒ¹é…ï¼ˆæ–‡æœ¬åŒºåŸŸåƒç´ çº§åŒ¹é…ï¼‰ï¼š
    - fg_gt: çœŸå€¼æ–‡æœ¬æ©ç ï¼ˆ1=æ–‡æœ¬ï¼Œ0=èƒŒæ™¯ï¼‰
    - fg_pred: é¢„æµ‹æ–‡æœ¬æ©ç ï¼ˆ1=æ–‡æœ¬ï¼Œ0=èƒŒæ™¯ï¼‰
    è¿”å›TP/FP/FNï¼ˆæ–‡æœ¬åŒºåŸŸçš„çœŸé˜³æ€§/å‡é˜³æ€§/å‡é˜´æ€§ï¼‰
    """
    if fg_gt is None or fg_pred is None:
        return 0, 0, 0

    # é‚»åŸŸè†¨èƒ€åŒ¹é…ï¼ˆå…¼å®¹å°èŒƒå›´åç§»ï¼‰
    struct = np.ones((2 * distance + 1, 2 * distance + 1), dtype=np.uint8)
    gt_dilated = binary_dilation(fg_gt, structure=struct)

    # è®¡ç®—TP/FP/FN
    TP = np.logical_and(fg_pred, gt_dilated).sum()  # é¢„æµ‹æ–‡æœ¬ä¸”åŒ¹é…çœŸå€¼
    FP = fg_pred.sum() - TP  # é¢„æµ‹æ–‡æœ¬ä½†æ— çœŸå€¼åŒ¹é…
    FN = fg_gt.sum() - TP  # çœŸå€¼æ–‡æœ¬ä½†æœªé¢„æµ‹

    return TP, FP, FN


def generate_prob_map(mask, sigma=SIGMA):
    """
    ä¸ºé¢„æµ‹æ©ç ç”Ÿæˆä¼ªæ¦‚ç‡å›¾ï¼ˆç”¨äºAP50è®¡ç®—ï¼‰ï¼š
    - è†¨èƒ€ç”Ÿæˆè½¯è¾¹ç¼˜ â†’ é«˜æ–¯æ¨¡ç³Š â†’ å½’ä¸€åŒ–åˆ°0-1
    """
    if mask is None or np.sum(mask) == 0:
        return np.zeros_like(mask, dtype=np.float32)

    # å¤šå°ºåº¦è†¨èƒ€ç”Ÿæˆæ¦‚ç‡æ¢¯åº¦
    dilated_1 = binary_dilation(mask, structure=np.ones((3, 3)))
    dilated_2 = binary_dilation(mask, structure=np.ones((5, 5)))

    # åŠ æƒèåˆï¼ˆæ ¸å¿ƒåŒºåŸŸæ¦‚ç‡é«˜ï¼‰
    prob_map = mask.astype(np.float32) * 1.0 + dilated_1.astype(np.float32) * 0.5 + dilated_2.astype(np.float32) * 0.2

    # é«˜æ–¯æ¨¡ç³Š+å½’ä¸€åŒ–
    prob_map = cv2.GaussianBlur(prob_map, (7, 7), sigma)
    prob_map = (prob_map - prob_map.min()) / (prob_map.max() - prob_map.min() + 1e-8)

    return prob_map


def calculate_ap50(precision, recall):
    """
    è®¡ç®—AP50ï¼ˆ11ç‚¹æ’å€¼æ³•ï¼ŒTotalTexté€šç”¨è¯„ä»·æ ‡å‡†ï¼‰ï¼š
    - éå†å¬å›ç‡0/0.1/.../1.0ï¼Œå–å¯¹åº”æœ€å¤§ç²¾ç¡®ç‡æ±‚å¹³å‡
    """
    if len(precision) == 0 or len(recall) == 0:
        return 0.0

    ap50 = 0.0
    recall_levels = np.linspace(0, 1, 11)  # 11ä¸ªå¬å›ç‡ç‚¹

    for r in recall_levels:
        mask = recall >= r
        if np.any(mask):
            ap50 += np.max(precision[mask]) / 11.0

    return ap50


def calculate_f1_from_tp_fp_fn(TP, FP, FN):
    """ä»TP/FP/FNè®¡ç®—F1-Score"""
    precision = TP / (TP + FP + 1e-8)
    recall = TP / (TP + FN + 1e-8)
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    return f1


# ===================== ä¸»è®¡ç®—æµç¨‹ =====================
def calculate_totaltext_metrics(gt_dir, pred_dir):
    # 1. åŒ¹é…æ–‡ä»¶åï¼ˆTotalTextæ–‡ä»¶åä¸€è‡´ï¼Œä»…åç¼€ä¸åŒï¼‰
    gt_files = {os.path.splitext(f)[0]: f for f in os.listdir(gt_dir) if os.path.splitext(f)[1].lower() in IMG_EXT}
    pred_files = {os.path.splitext(f)[0]: f for f in os.listdir(pred_dir) if os.path.splitext(f)[1].lower() in IMG_EXT}
    common_names = sorted(list(set(gt_files.keys()) & set(pred_files.keys())))

    if len(common_names) == 0:
        print("âŒ æ— åŒ¹é…çš„çœŸå€¼/é¢„æµ‹æ–‡ä»¶ï¼")
        return {
            "å¹³å‡PA": 0.0, "å¹³å‡fgIoU": 0.0, "å¹³å‡F1-Score": 0.0, "AP50": 0.0
        }

    print(f"âœ… åŒ¹é…åˆ° {len(common_names)} å¼ å›¾åƒ")

    # 2. åˆå§‹åŒ–å­˜å‚¨å˜é‡
    all_pred_probs = []  # æ‰€æœ‰åƒç´ çš„é¢„æµ‹æ¦‚ç‡ï¼ˆç”¨äºAP50ï¼‰
    all_gt_fg = []  # æ‰€æœ‰åƒç´ çš„çœŸå€¼å‰æ™¯ï¼ˆç”¨äºAP50ï¼‰
    pa_list = []  # å•å›¾PA
    fg_iou_list = []  # å•å›¾fgIoU
    f1_list = []  # å•å›¾F1-Score
    valid_count = 0  # æœ‰æ•ˆå¤„ç†å›¾åƒæ•°

    # 3. é€å›¾è®¡ç®—
    for name in tqdm(common_names, desc="è®¡ç®—TotalTextæŒ‡æ ‡"):
        # æ„é€ è·¯å¾„
        gt_path = os.path.join(gt_dir, gt_files[name])
        pred_path = os.path.join(pred_dir, pred_files[name])

        # åŠ è½½çœŸå€¼å’Œé¢„æµ‹æ©ç 
        gt_mask = load_mask(gt_path, is_gt=True)
        pred_mask = load_mask(pred_path, is_gt=False)

        if gt_mask is None or pred_mask is None:
            print(f"âš ï¸  è·³è¿‡ {name}ï¼šæ©ç åŠ è½½å¤±è´¥")
            continue

        # å°ºå¯¸æ ¡éªŒï¼ˆç¡®ä¿é¢„æµ‹ä¸çœŸå€¼å°ºå¯¸ä¸€è‡´ï¼‰
        if gt_mask.shape != pred_mask.shape:
            # å¼ºåˆ¶resizeé¢„æµ‹æ©ç åˆ°çœŸå€¼å°ºå¯¸
            pred_mask = cv2.resize(
                pred_mask,
                (gt_mask.shape[1], gt_mask.shape[0]),  # (W, H)
                interpolation=cv2.INTER_NEAREST
            )
            print(f"âš ï¸  {name} å°ºå¯¸ä¸åŒ¹é…ï¼Œå·²resizeï¼š{pred_mask.shape} â†’ {gt_mask.shape}")

        # ç”Ÿæˆé¢„æµ‹æ¦‚ç‡å›¾ï¼ˆç”¨äºAP50ï¼‰
        pred_prob = generate_prob_map(pred_mask)
        if pred_prob is None:
            print(f"âš ï¸  è·³è¿‡ {name}ï¼šæ¦‚ç‡å›¾ç”Ÿæˆå¤±è´¥")
            continue

        # å­˜å‚¨å…¨å±€æ•°æ®ï¼ˆå±•å¹³ä¸º1Dæ•°ç»„ï¼‰
        all_pred_probs.append(pred_prob.flatten())
        all_gt_fg.append(gt_mask.flatten())

        # è®¡ç®—å‰æ™¯åŒ¹é…ï¼ˆæ–‡æœ¬åŒºåŸŸï¼‰
        TP, FP, FN = edge_matching(gt_mask, pred_mask)
        total_pixels = gt_mask.size
        TN = total_pixels - (TP + FP + FN)  # èƒŒæ™¯æ­£ç¡®åƒç´ 

        # è®¡ç®—å•å›¾æŒ‡æ ‡
        # 1. PAï¼ˆåƒç´ ç²¾åº¦ï¼‰
        PA = (TP + TN) / total_pixels if total_pixels > 0 else 0.0
        # 2. fgIoUï¼ˆå‰æ™¯IoUï¼Œæ–‡æœ¬åŒºåŸŸIoUï¼‰
        fg_iou = TP / (TP + FP + FN + 1e-8)
        # 3. F1-Score
        f1 = calculate_f1_from_tp_fp_fn(TP, FP, FN)

        # å­˜å‚¨æŒ‡æ ‡
        pa_list.append(PA)
        fg_iou_list.append(fg_iou)
        f1_list.append(f1)
        valid_count += 1

    # è¾“å‡ºæœ‰æ•ˆè®¡æ•°
    print(f"\nğŸ“Š æœ‰æ•ˆå¤„ç†å›¾åƒæ•°ï¼š{valid_count}/{len(common_names)}")
    if valid_count == 0:
        return {
            "å¹³å‡PA": 0.0, "å¹³å‡fgIoU": 0.0, "å¹³å‡F1-Score": 0.0, "AP50": 0.0
        }

    # 4. è®¡ç®—å…¨å±€AP50
    concat_pred = np.concatenate(all_pred_probs)
    concat_gt = np.concatenate(all_gt_fg)
    precision, recall, _ = precision_recall_curve(concat_gt, concat_pred)
    ap50 = calculate_ap50(precision, recall)

    # 5. æ±‡æ€»ç»“æœ
    results = {
        "å¹³å‡PA": np.mean(pa_list),
        "å¹³å‡fgIoU": np.mean(fg_iou_list),
        "å¹³å‡F1-Score": np.mean(f1_list),
        "AP50": ap50
    }

    return results


# ===================== è¿è¡Œæµ‹è¯• =====================
if __name__ == "__main__":
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_totaltext_metrics(GT_DIR, PRED_DIR)

    # æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("TotalTextæ–‡æœ¬åˆ†å‰²æŒ‡æ ‡")
    print("=" * 60)
    for metric_name, value in metrics.items():
        print(f"{metric_name}: {value:.4f}")
    print("=" * 60)